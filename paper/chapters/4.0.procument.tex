

This study proposes a dynamic procurement based on machine learning techniques, trained with historical hourly data with custom made model architectures

\subsection{Methodology Implementation}

The methodology applied was a "brute force" choosing of better model, which can lead to better fine tuning results than a more complex architecture as shown in \cite{Liu2022}.\par
With multiple model related variables in study presented in Table~\ref{training_vars}:\par

\input{tables/muaddib_variables.tex}

For that we will study different architectures already proven to work in energy forecast \cite{Costa2022}, or in forecast in general \cite{Hewamalage2021}, such as \gls{FCNN}, \gls{LSTM}, \gls{CNN}. Testing also architectures proven to work in other fields, such as UNET \cite{Shelhamer2014} from image segmentation, or Transformers \cite{Vaswani2017}, the current machine learning state of art architecture. Although for Transformer, processing limitation won't allow for a deep study of potential the given problem.\par
As for the loss function used, we shall test it with the three most common regression loss function: \gls{MAE}, \gls{MSE}, \gls{MSLE}, which are means of the given error, in absolute terms, the square os the errors, and the logarithmic square, respectively. The last two functions give more importance to larger errors.\par
But since the problem we are trying to solve is not only of finding the smallest error, but to make sure the there is less negative and positive error than the benchmark we create a custom loss function to encapsulate the final loss calculation, the Mirror Weights. %\href{https://github.com/alquimodelia/alquitable/blob/main/alquitable/advanced_losses.py#L33}{Mirror Weights}. \par

This function acts as a weight distributor for the negative and positive errors, in such a way that the a ratio defines which size gives more meaning to the final loss calculation. This was created since the error in missing energy is on a $10^{5}$ dimension, and on surplus $10^{6}$.\par
In a default loss function trying to lower the absolute error, this difference means most work would be to lower surplus errors even at the expenses of raising the missing error. The created function allows for more behaviors, and some of them were studied, but the one with better results was defaulting surplus results weight 1, and making the weights of missing values its own error, multiplied by a ratio. Insights on given different ratio outcomes can be seen in Figure~\ref{fig:Ratio_influence_on_metrics}:\par


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{plots/article_ratio_mw.png}
    \caption{Mirror Weights Ratio Influence on Metrics}
    \label{fig:Ratio_influence_on_metrics}
  \end{figure}
Were the red doted line shows the benchmark values, and our goal is to have both below the benchmark line.\par
As for activation research suggested it could  provide significant impact on the outcome \cite{Vaswani2017,Liu2022}. The test were done using the most common activations for regression problems, where we separated activations inside the model structure (on each deep layer), and the final layer. These are: linear leaves inputs unchanged, \gls{ReLU} outputs the input if positive and zero otherwise, while \gls{GELU} smooth this behavior by applying a Gaussian-based probabilistic transformation. \par
And the last model variable in test were the weights, these given directly to the model training, not in a custom loss function. These weights are multiplied with the Mirror Weights.\par
Temporal weights give weight one to the oldest sample and add one per time sample, making older data less relevant, in an attempt to be more aware of latest trends. The distance to mean purpose is to give more weight values further away from the mean, this would serve as a way to alleviate mean related generalization and catch spike inducing patterns.\par
Where each of the model variables in study is a layer of training, giving the best model within that scope we would go to the next variable with the given best option so far. Going back and forward as to not loose best possible choices.\par


\begin{figure}[H]
	\centering
	\resizebox{\linewidth}{!}{\input{tables/methodoly_training.tex}}
	\caption{Model Choice Method Scheme.}
	\label{fig:method_training}
\end{figure}

For the purpose of controlling and processing this experiment three python packages were created.

\begin{itemize}
    \item Alquimodelia: A keras based model builder package, to create the necessary models with each different arch and variable.
    \item Alquitable: A keras based workshop package, to create custom callbacks, loss functions, data generators.
    \item MuadDib: A machine learning framework that uses Alquimodelia to test and choose best models on given conditions automatically.
\end{itemize}

The experiments were done using keras>=3, a high-level deep learning library that simplifies the implementation of neural networks, with a torch backend on a CPU laptop.

% \subsubsection{Advance Loss Function}


% Para escolher a melhor maneira de distribuir pesos foi criada uma função de perda com diferentes regras, que distribuem o peso da amostra:
% \href{https://github.com/alquimodelia/alquitable/blob/main/alquitable/advanced_losses.py#L33}{Mirror Weights (Pesos Espelhados)},
% que vai distribuir os pesos da amostra consoante um rácio predefinido e o próprio erro da amostra.\par
% Os pesos nas amostras vão ser divididos entre os erros negativos (alocação em demasia) e os positivos (alocação em falta). Consoante uma variável lógica,  uns terão peso 1 e os outros serão o próprio erro em absoluto. Dando assim um peso equivalente ao erro, quanto maior o erro maior o peso da amostra na função de perda, do lado da amostra escolhido (em demasia ou em falta).\par
% O rácio pode ser multiplicado um rácio tanto a um dos pesos como a outro, sendo estes rácios que irão equilibrar as diferenças entre a alocação em falta e a em demasia. Refira-se que o sinal do rácio influencia qual o lado a ser multiplicado.\par
% Este pesos são passados directamente à função de perda em uso.\par


% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\textwidth]{plots/ratio_mw.png}
%     \caption{Resultados de alocações totais em diferentes rácios}
%     \label{fig:resexpratiomw}
%   \end{figure}

% Estas variações no rácio produzem diferentes dimensões nas alocações, modificando assim a sua posição em relação ao \textit{benchmark}. Aqui para cada arquitetura o rácio ideal para o melhor GPD Positivo diferencia ligeiramente, tendo sido procurado com tentativa/erro baseado em assunções perante a aparente distribuição rácio/alocações.\par


\subsection{Metrics}
\input{chapters/4.1.2.metrics.tex}


% To address the challenges introduced by \gls{vRES}, dynamic reserve procurement methods have been proposed. Unlike static methods, dynamic approaches consider real-time or near real-time forecasts of energy demand and renewable generation, allowing \gls{TSO}s to adjust reserve allocations accordingly. This adaptability reduces over-procurement and minimizes costs, improving the efficiency of reserve markets.

% The adoption of advanced forecasting tools, particularly machine learning techniques, is central to enabling dynamic reserve procurement. By leveraging historical and operational data, machine learning models can predict reserve needs with greater accuracy, addressing the uncertainties associated with \gls{vRES} generation. Studies have shown that these models outperform traditional statistical methods, offering significant improvements in reserve management and cost reduction.

% In conclusion, the evolving electricity markets and ancillary services frameworks must adapt to the challenges posed by high \gls{vRES} penetration. Dynamic reserve procurement, supported by advanced forecasting techniques and market design improvements, offers a path toward more efficient and reliable power systems.


% The dynamic procurement of secondary reserves represents a significant step forward in addressing the inefficiencies inherent in traditional static allocation methods. Unlike static reserve procurement, which relies on fixed ratios or historical averages, dynamic approaches incorporate real-time forecasts and system conditions to adjust reserve requirements. This adaptability is particularly critical for modern electricity systems with high penetration of \gls{vRES}, where forecasting uncertainty and rapid changes in generation output challenge grid stability.

% Dynamic reserve procurement involves estimating upward and downward reserve needs based on the expected deviations between day-ahead scheduled generation and real-time demand. By leveraging advanced forecasting tools, such as machine learning models, it becomes possible to predict these deviations with greater accuracy, optimizing the allocation of secondary reserves. Historical data on vRES production, system demand, and grid imbalances serve as inputs to these models, allowing the identification of patterns and trends that inform reserve procurement decisions.

% Machine learning techniques, including \gls{LSTM} networks and other time-series forecasting models, have demonstrated significant potential for improving reserve predictions \cite{Costa2022}\cite{Benti2023}. These models can capture the nonlinear and temporal dependencies present in renewable energy data, outperforming traditional statistical methods such as ARIMA. By incorporating real-time weather forecasts, generation data, and demand profiles, dynamic approaches ensure that reserve procurement aligns more closely with actual system needs, reducing both over-procurement and under-procurement of reserves.

% The dynamic approach also allows for asymmetrical procurement of upward and downward reserves, which is particularly relevant in systems with variable renewable generation. For instance, during periods of high solar generation, upward reserves may be less critical, whereas downward reserves become essential to accommodate excess production. Conversely, during low renewable output, upward reserves are prioritized to address potential generation shortfalls.

% In summary, dynamic procurement of secondary reserves offers a more efficient and adaptive solution to balancing challenges in modern electricity systems. By leveraging machine learning techniques and real-time forecasts, this approach enhances reserve allocation, reduces operational costs, improving penetration of \gls{vRES}.

% \input{chapters/4.1.0.context.tex}
% \input{chapters/4.1.1.model_archs.tex}
