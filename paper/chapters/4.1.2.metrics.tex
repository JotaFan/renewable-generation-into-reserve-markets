
With distinct weights, the metrics, are used to choose best model on each iteration, and they can be divided into two groups:

\begin{enumerate}
\item Model metrics, where we just use the usual regression metrics adding a metric for how much did the model missed in allocating for the validation period.
\item Comparative metrics, where we assert percentage gains over the current allocation method. 
\end{enumerate} 

\subsubsection{Model Metrics}
\begin{linenomath}
    \begin{equation}\label{eq:rmse}
        RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n}(t_i - p_i)^2}
    \end{equation}
    \end{linenomath}
		
		where $t$ is the observed value, $p$ is the forecast and $n$ is the number of samples.

\begin{linenomath}
    \begin{equation}\label{eq:SAE}
        SAE = \sum_{i=1}^{n}\left|t_i - p_i \right|
    \end{equation}
    \end{linenomath}

SAE can be divide into the following metrics, where we obtain the error, within the time period, of allocated energy not enough for the needs, and too much energy allocated, separately.\\

The \gls{AllocM} is computed as follows:
\begin{linenomath}
    \begin{equation}\label{eq:AllocM}
        AllocM = \sum_{i=1}^{n}\left|t_i - p_i \right| , \text{if } p_i < t_i
        \end{equation}
    \end{linenomath}

The \gls{AllocS} is computed as follows:

\begin{linenomath}
    \begin{equation}\label{eq:AllocS}
        AllocS = \sum_{i=1}^{n}\left|t_i - p_i \right| , \text{if } p_i > t_i
            \end{equation}
    \end{linenomath}
		
These metrics are needed to get a better error than the benchmark, but also to have less wasted \gls{AllocM}, and less occurrences of \gls{AllocS}.\par

\subsubsection{Model/benchmark comparative metrics}

\gls{PPG} is the percentage of how much better is the model over the benchmark, it is computed as follows: 
\begin{linenomath}
    \begin{equation}\label{eq:PPG}
        PPG = \frac{SAE_{benchmark} - SAE_{model}}{SAE_{benchmark}} \times 100
    \end{equation}
    \end{linenomath}
		
The following metrics are the same but for only missing allocation and surplus allocation.\\
\gls{PPGM} computes the performance of the missing allocation as follows:\\

\begin{linenomath}
    \begin{equation}\label{eq:PPGM}
        PPGM = \frac{AllocM_{benchmark} - AllocM_{model}}{AllocM_{benchmark}} \times 100
    \end{equation}
    \end{linenomath}
		
\gls{PPGM} computes the performance of the surplus allocation as follows:

\begin{linenomath}
    \begin{equation}\label{eq:PPGS}
        PPGS = \frac{AllocS_{benchmark} - AllocS_{model}}{AllocS_{benchmark}} \times 100
    \end{equation}
    \end{linenomath}

The \gls{PPG}Positive metric is showing how much better is the model over the benchmark, but only if \gls{PPGM} and \gls{PPGM} are positive.\\

\begin{linenomath}
    \begin{equation}\label{eq:PPGPositive}
        PPG Positive = 
        \begin{cases} 
            PPG & , \text{if } PPGM \text{ }\&\text{ } PPGS \geq 0 \\
            0 & , \text{if } PPGM \text{ }\|\text{ } PPGS < 0 \\
        \end{cases} 
        \end{equation}
    \end{linenomath}
