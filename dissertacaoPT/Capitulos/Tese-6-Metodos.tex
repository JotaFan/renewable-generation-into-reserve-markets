\chapter{Métodos}

Neste capitulo percorremos as experiências realizadas. Estas foram feitas atraves do usos do programas criados para o efeito, disponiveis no repositorio GitHub do \href{https://github.com/JotaFan/renewable-generation-into-reserve-markets}{projecto}.\\

\section{Benchmark}

Como modelo bencharmark iremos usar a alocação feita. Pois são estes valores que procuramos melhorar no caso prático.\\



\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/benchmark.png}
    \caption{Serie Temporal do benchmark}
    \label{fig:benchmark}
\end{figure}
  

\begin{table}[H]
    \caption{Dados Benchmark}
    \resizebox{\linewidth}{!}{\csvautotabular{../data/benchmark_scores.csv}\label{tb:benchmark}}       
\end{table}


Para validação dos mesmo, vamos usar o ano 2021, devido aquele salto nos valores de alocação em 2022.\\

Para esses temos os seguintes dados:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/benchmark_validation.png}
    \caption{Serie Temporal do benchmark 2021}
    \label{fig:benchmark_validation}
\end{figure}
  

Os metodos em estudo vão ser comparados a esta medida. Sendo que o principal é baixar tanto a alocação perdida, como a alocação a mais. Que se traduzem no erro absoluto.\\

\begin{table}[H]
    \caption{Dados Benchmark de validação}
    \resizebox{\linewidth}{!}{\csvautotabular{../data/benchmark_validation_scores.csv}  \label{tb:benchmark_val}}      
\end{table}

\section{Modelos estatiscos\label{se:model_stats}}

Antes de entrar para o densenvolvimento de modelos vamos usar metódos e modelos abertos para usar comparativamente.\\

Os modelos estatiscos recurrentes em previsões são AR, MA, ARMA, ARIMA, SARIMA para previsões so com um atributo, e para multiplos atributos VAR.\\
O modelo AR e o VAR não obtiveram resultados aplicaveis, logo foram desconsiderado.\\

\subsection{Univariate Analysis}

Estas análises apenas aplicam uma formula à variavel em questão.

\subsubsection{AR}
\begin{equation} \label{eq:AR} 
    y_t = \beta_0 + \beta_1 y_{t-1} + \dots + \beta_p y_{t-p} + \epsilon_t 
\end{equation}
onde:
\begin{itemize}
  \item $y_t$: O valor da serie no tempo $t$.
  \item $p$: O numero de atrasos.
  \item $\epsilon_t$: O barulho no tempo $t$.
  \item $\beta$: O coeficiente dos valores em atrasdo.
\end{itemize}

\subsubsection{MA}
MA - Moving Average

A MA 


\begin{equation} \label{eq:MA} 
    y_t = c + \epsilon_t + \theta_1 \epsilon_{t-1} + \dots + \theta_q \epsilon_{t-q}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/MA_model.png}
    \caption{Previsões 2021 com modelo MA}
    \label{fig:MA_model}
\end{figure}
  
\subsection{ARMA}

AR eé blabla

\begin{equation} \label{eq:ARMA}  y_t = \beta_0 + \beta_1 y_{t-1} + \dots + \beta_p y_{t-p} + \epsilon_t + \theta_1 \epsilon_{t-1} + \dots + \theta_q \epsilon_{t-q}  \end{equation}
\textbf{ARMA (Autoregressive Moving Average) Model:}
\begin{itemize}
  \item{$y_t$: The value of the time series at time $t$.}
  \item $p$: The number of time lags to regress on (AR part).
  \item $q$: The number of time lags of the error term to regress on (MA part).
  \item $\epsilon_t$: The error term at time $t$.
  \item $\beta$: The coefficients of the lagged values (AR part).
  \item $\theta$: The coefficients of the lagged error terms (MA part).
\end{itemize}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/ARMA_model.png}
    \caption{Previsões 2021 com modelo ARMA}
    \label{fig:ARMA_model}
\end{figure}

\subsection{ARIMA}

AR eé blabla

\begin{equation} \label{eq:ARIMA}y_t^d = \beta_0 + \beta_1 y_{t-1}^d + \dots + \beta_p y_{t-p}^d + \epsilon_t^d + \theta_1 \epsilon_{t-1}^d + \dots + \theta_q \epsilon_{t-q}^d \end{equation}
\textbf{ARIMA (Autoregressive Integrated Moving Average) Model:}
\begin{itemize}
  \item $y_t^{[d]}$: The differenced value of the time series at time $t$.
  \item $p$: The number of time lags to regress on (AR part).
  \item $d$: The order of differencing.
  \item $q$: The number of time lags of the error term to regress on (MA part).
  \item $\epsilon_t^{[d]}$: The differenced error term at time $t$.
  \item $\beta$: The coefficients of the lagged values (AR part).
  \item $\theta$: The coefficients of the lagged error terms (MA part).
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/ARIMA_model.png}
    \caption{Previsões 2021 com modelo ARIMA}
    \label{fig:ARIMA_model}
\end{figure}

\subsection{SARIMA}

AR eé blabla



AR eé blabla

\begin{equation} \label{eq:SARIMA} y_t^{[m]d} = \beta_0 + \beta_1 y_{t-m}^{[m]d} + \dots + \beta_p y_{t-pm}^{[m]d} + \epsilon_t^{[m]d} + \theta_1 \epsilon_{t-m}^{[m]d} + \dots + \theta_q \epsilon_{t-qm}^{[m]d} \end{equation}

\textbf{SARIMA (Seasonal Autoregressive Integrated Moving Average) Model:}
\begin{itemize}
  \item $y_t^{[m]d}$: The differenced value of the time series at time $t$.
  \item $p$: The number of time lags to regress on (AR part).
  \item $d$: The order of differencing.
  \item $q$: The number of time lags of the error term to regress on (MA part).
  \item $m$: The number of time lags comprising one full period of seasonality.
  \item $\epsilon_t^{[m]d}$: The differenced error term at time $t$.
  \item $\beta$: The coefficients of the lagged values (AR part).
  \item $\theta$: The coefficients of the lagged error terms (MA part).
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/SARIMA_model.png}
    \caption{Previsões 2021 com modelo SARIMA}
    \label{fig:SARIMA_model}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../plots/VAR model_model.png}
    \caption{Previsões 2021 com modelo VAR}
    \label{fig:VAR_model}
\end{figure}









\subsection{Resultados\label{se:statitics_scores}}

\begin{table}[H]
    \caption{Resultados modelos Estatísticos}
    \resizebox{\linewidth}{!}{\input{../statistical_models/stats_scores.tex}\label{tb:statitics_scores}}      
\end{table}

Apenas pelos métodos estatisticos verificamos que no ano de 2021 teria havido uma melhoria de cerca de 80\% das vezes, usando qualquer um dos métodos apresentados.\\
Embora a alocação em falta seja de uma ordem de grandeza superior.\\


\section{Forecat\label{se:forecat}}


Com o propósito de desenvolver este estudo, e deixar ferramentas para a replicação do mesmo, foi criado uma biblioteca em python para desenhar as arquitecturas em estudo.\\
TODO: url

\subsection{Construtor de modelos}

Seguindo as arquitecturas descritas anteriormente esta ferramenta constroi os modelos automáticamente, sendo que precisamos apenas de fornecer os parametros variáveis.\\
O construtor assenta na idea de três camadas abstrastas de redes neuronais. A camada de entrada, a camada de bloco, e a camada intrepertativa.\\
A camada de entrada recebe os dados e normaliza, podendo tambem fazer outras operações de preparação para a camada de bloco.\\
A camada de bloco é a camada descritiva da arquitetura, é a que tem as operações fundamentais.\\
A camada interpretativa é a que recebe o sinal de multiplas redes neuronais internas, e traduz para o objectivo, usando Dense layers. \\

Esta abstração segue sempre esta ordem. As variaçoes dentro de cada arquitetura dependem das hiperparametrizações das mesmas, ou de cada camada, ou então da repetição do circuito, em paralelo ou em série. ou uma combinação destes.\\

\subsection{Gerador de dados}

O gerador construido trata da formataçao dos dados para entrada nos modelos. Formatação esse que se baseia nos valores de janelas temporais a usar, e na divisão treino/teste.\\
Esta ferramenta agrega os dados em tensores de formato \textit{(N, t, a)}, onde \textit{N} é o numero do casos, \textit{t} é a janela temporal, e \textit{a} é o numero de atributos.\\
A ferramenta permite tambem definir o tempo de salto entre cada entrada.\\
Usando como exemplo uma janela temporal de 168 (horas, uma semana) para treino, e 24 (horas) para o alvo. Com um salto temporal de 1 a primeira entrada teria como treino as primeiras 168 horas dos dados, e como alvo as 24 horas consequentes. A segunda entrada seria a partir da segunda hora dos dados, e assim consecutivamente. Para um caso em que o tempo de salto seria 24, a primeira entrada mantinha-se, mas a segunda começaria 24 horas depois, e não apenas uma.\\

Como estamos tambem a lidar com dados desfasados, o gerador permite um TODO: shift em atributos a especificar. No caso em estudo temos que os atributos são de DA (day-ahead), logo estão desfasados 24 horas. O que implica termos de aplicar este shift nos dados que não são DA, nomeadamente os dados alvo. Esta propriedade permite tambem o facil uso da ferramenta noutros dados desfasados, como as previsões a 3 ou 8 horas.\\


\section{Treino e Resultados\label{se:training}}

Realizaram-se várias experiências, onde em cada um se ia elimando alguns dos objectos em estudo.\\
Em casa experiências toda a parametrização era igual, à excepção do objecto de estudo.\\

\subsection{Arquiteturas e numeros de epocas}

Nesta experiência foi testado o resultado das várias arquiteturas em estudo, como também o impacto do numero de epocas na qualidade dos modelos.\\
As arquitecturas estudadas foram:

%TODO: arranjar reseach para cada uma 

\begin{itemize}
    \item[--] VanillaDense
    \item[--] VanillaCNN
    \item[--] VanillaLSTM
    \item[--] StackedCNN
    \item[--] StackedLSTM
    \item[--] EncoderDecoder
    \item[--] UNET
\end{itemize}

O modelos foram treinados em 200 epocas, sendo que foram salvos a cada 10 epocas, de forma conseguirmos perceber os contextos nos saltos de epocas.\\

As parametrizações usadas:
\begin{itemize}
    \item[--] loss : mean squared error
    \item[--] Metodo activação no meio : relu
    \item[--] Metodo activação no fim : relu
    \item[--] optimizador : Adam
    \item[--] Janela temporal em X : 168 horas (1 semana)
    \item[--] Janela temporal em Y : 24 horas (1 semana)
    \item[--] Fracção de treino : 95\%  
\end{itemize}

\subsection{Funções de Perda (Loss)}

TODO: o que é a loss function?

Esta experiência consiste em rever que função de perda é melhor aplicavel ao problema. Sendo um problema de regressao linear, de valores bastante oscilatórios e com uma distribuição exponencial, temos algumas loss functions que já são reconhecidas para o problema.\\


(NLE) loss function %\cite{Deep Uncertainty Quantification: A Machine Learning Approach for Weather Forecasting}

\begin{itemize}
    \item[--] mean absolute error
    \item[--] mean squared error    
    \item[--] loss : mean absolute error

\end{itemize}



\subsection{Hiperparametrização}

\subsubsection{Activação}

\subsubsection{Optimizadores}

\subsection{Janelas Temporais}

Um dos pontos deste trabalho é perceber a fesiabilidade de usar dados de previsão do dia anterior (DA) para estes atributos energéticos.\\
Algo que pode ser também aplicado no futuro a outros dados que não DA, mas sim a 3 horas, ou a 8 horas.\\
Para perceber esta flexibilidade, mas especialmente para escolher as melhores janelas temporais a usar neste modelos, vamos testar várias combinações.\\
Mantendo em mente que o objectivo é prever 24 horas, para os casos onde o alvo não dá um previsão de 24 horas, é necessario criar um numero de modelos para fazer as 24 horas.\\
Para validação apenas é usado o espaço temporar previsto, e não multiplos modelos.\\
Dado as análises de autocorrelação iremos usar como janelas para treino o conjunto [24, 48, 98, 168] para prever o conjunto [1, 4, 8, 12, 24]\\
Para alem destes foram também testadas combinações com janelas de treino 8 e 12 horas. Estas mostraram rapidamente que janelas de treino menores que as de previsão funcionam muito mal.\\

\subsection{Classificação}

Como descrito em (ref)... existe também o uso de tanto classes como valores linears para resoluçao de problemas de regressão, também chamado \textit{cluster-wise regression}.\\
Para este teste mudamos um pouco o modelo em uso. Ao invés de apenas uma camada interpretativa, fazemos duas, em paralelo, sendo que uma resolve a regressão e a outra a classificação.\\
Outro caso, proposto aqui, é usar uma nova camada intrepertativa, que combina as duas saidas anteriores (linear e classificação), e resolve novamente para os valores lineares.\\
Estes modelos não teram apenas uma saida, mas varias, como as arquiteturas MultiTail, mas neste caso cada uma resolve para um problema diferente, com funções de perda, e activações diferentes.\\

TODO: desenho destas duas camadas intrepretaticas

\subsection{Pesos}

Por ultimo foi testado o impacto do uso de pesos nos modelos. Estes pesos são o peso que aquele alvo TODO: epxlicar pesos

\subsubsection{Modelos lineares}

Para os modelos lineares o peso que é adiciona ao modelo é a distância à média.\\
Este peso serve para dar mais importância a valores facilmente considerados outliers.\\



\subsubsection{Modelos Lineares e de Classificação}
Aqui o peso é dado por saida. Para as saidas lineares o peso dados é o mesmo que apresentado anteriormente, para a saida de classificaçao, o peso é o inverso da frequência da classe.\\
Distribuindo assim a importância de treino pela frquência das classes. Sendo um prática comum especialmente quando as distribuiçoes são muito desiguais, como o caso em estudo.\\
É aqui estudada a aplicaçao destes pesos individualmente, e em conjunto. \\
Os pesos aqui são tambem normalizados de modo a que o maior peso em cada um deles seja 1, e logo a multiplicaçao dos dois esteja dentro das mesmas dimensões de relevância.\\


\begin{equation} \label{eq:peso_media} 
    P_m = \left| y - mean \right| 
\end{equation}

\section{Considerações adicionais  \label{se:metodos_plus}}

Foram realizados testes adicionais que não obtiveram resultados passivos de boa interpretação, e foram imediatamente descartados, como:

\begin{itemize}
    \item[--] Janela temporal em X : 96, 48, 24
    \item[--] optimizador : todos os optimizadores disponiveis na biblioteca keras
    \item[--] loss : todas as outra loss functions de regressão disponiveis.
    \item[--] epocas : influência do numero de epocas nos modelos, foram treinados até 20000 epocas alguns modelos mas à medida que a perda ia estagnando na assintomta, o modelo ia apenas piorando.
\end{itemize}


Todos os metodos foram realizados utilizando código em python, que está aberto em https://github.com/JotaFan/renewable-generation-into-reserve-markets
